name,ring,quadrant,isNew,description
Platform engineering product teams,Trial,Techniques,FALSE,"<p>The adoption of cloud and DevOps — while increasing the productivity of teams who can now move more quickly with reduced dependency on centralized operations teams and infrastructure — also has constrained teams that lack the skills to self-manage a full application and operations stack. Some organizations have tackled this challenge by creating <strong>platform engineering product teams</strong>. These teams maintain an internal platform that enables delivery teams to deploy and operate systems with reduced lead time and stack complexity. The emphasis here is on API-driven self-service and supporting tools, with delivery teams still responsible for supporting what they deploy onto the platform. Organizations that consider establishing such a platform team should be very cautious not to accidentally create a <a href=""/radar/techniques/separate-devops-team"">separate DevOps team</a>, nor should they simply relabel their <a href=""/radar/platforms/superficial-private-cloud"">existing hosting and operations structure</a> as a platform. If you're wondering how to best set up platform teams, we've been using the concepts from <a href=""https://teamtopologies.com/"">Team Topologies</a> to split platform teams in our projects into enablement teams, core ""platform within a platform"" teams and stream-focused teams.</p>"
Zero trust architecture (ZTA),Trial,Techniques,FALSE,"<p>The technology landscape of organizations today is increasingly more complex with assets — data, functions, infrastructure and users — spread across security boundaries, such as local hosts, multiple cloud providers and a variety of SaaS vendors. This demands a paradigm shift in enterprise security planning and systems architecture, moving from static and slow-changing security policy management, based on trust zones and network configurations, to dynamic, fine-grained security policy enforcement based on temporal access privileges.</p>

<p><strong>Zero trust architecture (ZTA)</strong> is an organization's strategy and journey to implement zero-trust security principles for all of their assets — such as devices, infrastructure, services, data and users — and includes implementing practices such as securing all access and communications regardless of the network location, enforcing policies as code based on the least privilege and as granular as possible, and continuous monitoring and automated mitigation of threats. Our Radar reflects many of the enabling techniques such as <a href=""/radar/techniques/security-policy-as-code"">security policy as code</a>, <a href=""/radar/techniques/sidecars-for-endpoint-security"">sidecars for endpoint security</a> and <a href=""/radar/techniques/beyondcorp"">BeyondCorp</a>. If you're on your journey toward ZTA, refer to the <a href=""https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-207-draft2.pdf"">NIST ZTA publication</a> to learn more about principles, enabling technology components and migration patterns as well as Google's publication on <a href=""https://cloud.google.com/security/beyondprod"">BeyondProd</a>.</p>"
Preflight builds,Assess,Techniques,FALSE,"<p>Even though we strongly advocate in favor of CI rather than <a href=""/radar/techniques/gitflow"">Gitflow</a>, we know that <a href=""https://trunkbaseddevelopment.com/committing-straight-to-the-trunk/"">committing straight to the trunk</a> and running the CI on a master branch can be ineffective if the team is too big, the builds are slow or flaky, or the team lacks the discipline to run the full test suite locally. In this situation a red build can block multiple devs or pairs of devs. Instead of fixing the underlying root cause — slow builds, the inability to run tests locally or monolithic architectures that necessitate many people working in the same area — teams usually rely on feature branches to bypass these issues. We discourage feature branches, given they may require significant effort to resolve merge conflicts, and they introduce longer feedback loops and potential bugs during conflict resolution. Instead, we propose using <strong>preflight builds</strong> as an alternative: these are pull request–based builds for “micro branches” that live only for the duration of the pipeline run, with the branch opened for every commit. To help automate this workflow, we've come across bots such as <a href=""https://bors.tech/"">Bors</a>, which automates merging to master and branch deletion in case the mini branch build succeeds. We're assessing this flow, and you should too; but don't use this to solve the wrong problem, as it can lead to misuse of branches and may cause more harm than benefit.</p>"
Long-lived branches with Gitflow,Hold,Techniques,FALSE,"<p>Five years ago we highlighted the problems with <strong>long-lived branches with Gitflow</strong>. Essentially, long-lived branches are the opposite of continuously integrating all changes to the source code, and in our experience continuous integration is the better approach for most kinds of software development. Later we extended our caution to <a href=""/radar/techniques/gitflow"">Gitflow</a> itself, because we saw teams using it almost exclusively with long-lived branches. Today, we still see teams in settings where continuous delivery of web-based systems is the stated goal being drawn to long-lived branches. So we were delighted that the author of Gitflow has now added a note to his <a href=""https://nvie.com/posts/a-successful-git-branching-model/"">original article</a>, explaining that Gitflow was not intended for such use cases.</p>"
Snapshot testing only,Hold,Techniques,FALSE,"<p>The value of snapshot testing is undeniable when working with legacy systems by ensuring that the system continues to work and the legacy code doesn't break. However, we're seeing the common, rather harmful practice of using <strong>snapshot testing only</strong> as the primary test mechanism. Snapshot tests validate the exact result generated in the DOM by a component, not the component's behavior; therefore, it can be weak and unreliable, fostering the ""only delete the snapshot and regenerate it"" bad practice. Instead, you should test the logic and behavior of the components emulating what users would do. This mindset is encouraged by tools in the <a href=""https://testing-library.com/docs/guiding-principles"">Testing Library</a> family.</p>"
Anka,Trial,Platforms,FALSE,"<p><strong><a href=""https://ankadoc.bitbucket.io/"">Anka</a></strong> is a set of tools to create, manage, distribute, build and test macOS reproducible virtual environments for iOS and macOS. It brings Docker-like experience to macOS environments: instant start, CLI to manage virtual machines and registry to version and tag virtual machines for distribution. We've used Anka to build a macOS private cloud for a client. This tool is worth considering when virtualizing iOS and macOS environments.</p>"
OpenTelemetry,Trial,Platforms,FALSE,"<p><strong><a href=""https://opentelemetry.io/"">OpenTelemetry</a></strong> is an open source observability project that merges <a href=""https://opentracing.io/"">OpenTracing</a> and <a href=""https://github.com/census-instrumentation"">OpenCensus</a>. The OpenTelemetry project includes <a href=""https://github.com/open-telemetry/opentelemetry-specification"">specification</a>, libraries, agents, and other components needed to capture telemetry from services to better observe, manage and debug them. It covers the three pillars of observability — distributed tracing, metrics and logging (currently in beta) — and its specification connects these three pieces through <a href=""https://github.com/open-telemetry/opentelemetry-specification/blob/master/specification/correlationcontext/api.md"">correlations</a>; thus you can use <em>metrics</em> to pinpoint a problem, locate the corresponding <em>traces</em> to discover where the problem occured, and ultimately study the corresponding <em>logs</em> to find the exact root cause. OpenTelemetry components can be connected to back-end observability systems such as <a href=""/radar/tools/prometheus"">Prometheus</a> and <a href=""/radar/tools/jaeger"">Jaeger</a> among <a href=""https://opentelemetry.io/registry/?s=exporter"">others</a>. Formation of OpenTracing is a positive step toward the convergence of standardization and the simplification of tooling.</p>"
Anthos,Assess,Platforms,FALSE,"<p>We see a shift from accidental hybrid or whole-of-estate cloud migration plans to intentional and sophisticated hybrid, poly or portable cloud strategies, where organizations apply multidimensional principles to establish and execute their cloud strategy: where to host their various data and functional assets based on risk, ability to control and performance profiles; how to utilize their on-premise infrastructure investments while reducing the cost of operations; and how to take advantage of multiple cloud providers and their unique differentiated services without creating complexity and friction for users building and operating applications.</p>

<p><strong><a href=""https://cloud.google.com/anthos"">Anthos</a></strong> is Google's answer to enable hybrid and multicloud strategies by providing a high-level management and control plane on top of a set of open source technologies such as <a href=""https://cloud.google.com/anthos/gke"">GKE</a>, <a href=""https://cloud.google.com/anthos/service-mesh"">Service Mesh</a> and a Git-based <a href=""https://cloud.google.com/anthos/config-management"">Configuration Management</a>. It enables running portable workloads and other assets on different hosting environments, including Google Cloud and on-premises hardware. Although other cloud providers have comparative offerings, Anthos intends to go beyond a hybrid cloud to a portable cloud enabler using open source components, but that is yet to be seen. We're seeing a rising interest in Anthos. While Google's approach in managed hybrid cloud environments seems promising, it’s not a magic bullet and requires changes in both existing cloud and on-premise assets. Our advice for clients considering Anthos is to make measured tradeoffs between selecting services from the Google Cloud ecosystem and other options, to maintain their right level of neutrality and control.</p>"
Dojo,Trial,Tools,FALSE,"<p>A few years ago, Docker — and containers in general — radically changed how we think about packaging, deploying and running our applications. But despite this improvement in production, developers still spend a lot of time setting up development environments and regularly run into ""but it works on my machine"" style problems. <strong><a href=""https://github.com/kudulab/dojo"">Dojo</a></strong> aims to fix this by creating standard development environments, versioned and released as Docker images. Several of our teams use Dojo to streamline developing, testing and building code from local development through production pipelines.</p>"
mkcert,Trial,Tools,FALSE,"<p><strong><a href=""https://github.com/FiloSottile/mkcert"">mkcert</a></strong> is a convenient tool for creating locally trusted development certificates. Using certificates from real certificate authorities (CAs) for local development can be challenging if not impossible (for hosts such as example.test, localhost or 127.0.0.1). In such situations self-signed certificates may be your only option. mkcert lets you generate self-signed certificates and installs the local CA in the system root store. For anything other than local development and testing, we strongly recommend using certificates from real CAs to avoid trust issues.</p>"
AsyncAPI,Assess,Tools,FALSE,"<p>Open standards are one of the foundational pillars of building distributed systems. For example, the <a href=""https://github.com/OAI"">OpenAPI (formerly Swagger)</a> specification, as an industry standard to define RESTful APIs, has been instrumental to the success of distributed architectures such as <a href=""https://martinfowler.com/articles/microservices.html"">microservices</a>. It has enabled a proliferation of tooling to support building, testing and monitoring RESTful APIs. However, such standardizations have been largely missing in distributed systems for <a href=""https://martinfowler.com/articles/201701-event-driven.html"">event-driven APIs</a>.</p>

<p><strong><a href=""https://www.asyncapi.com/"">AsyncAPI</a></strong> is an open source initiative to create a much needed event-driven and asynchronous API standardization and development tooling. The <a href=""https://www.asyncapi.com/docs/specifications/2.0.0/"">AsyncAPI specification</a>, inspired by the OpenAPI specification, describes and documents event-driven APIs in a machine-readable format. It's protocol agnostic, so it can be used for APIs that work over many protocols, including MQTT, WebSockets, and Kafka. We're eager to see the ongoing improvements of AsyncAPI and further maturity of its tooling ecosystem.</p>"
Gloo,Assess,Tools,FALSE,"<p>With the increasing adoption of <a href=""/radar/platforms/kubernetes"">Kubernetes</a> and <a href=""/radar/techniques/service-mesh"">service mesh</a>, API gateways have been experiencing an existential crisis in cloud-native distributed systems. After all, many of their capabilities (such as traffic control, security, routing and observability) are now provided by the cluster’s ingress controller and mesh gateway. <strong><a href=""https://www.solo.io/products/gloo/"">Gloo</a></strong> is a lightweight API gateway that embraces this change; it uses <a href=""https://www.envoyproxy.io/"">Envoy</a> as its gateway technology, while providing added value such as a cohesive view of the APIs to the external users and applications. It also provides an administrative interface for controlling Envoy gateways and runs and integrates with multiple service mesh implementations such as <a href=""https://linkerd.io/"">Linkerd</a>, <a href=""/radar/platforms/istio"">Istio</a> and <a href=""https://aws.amazon.com/app-mesh/"">AWS App Mesh</a>. While its open source implementation provides the basic capabilities expected from an API gateway, its enterprise edition has a more mature set of security controls such as API key management or integration with <a href=""/radar/tools/open-policy-agent-opa"">OPA</a>. Gloo is a promising lightweight API gateway that plays well with the ecosystem of cloud-native technology and architecture, while avoiding the API gateway trap of enabling business logic to glue APIs for the end user.</p>"
Karate,Trial,languages-and-frameworks,FALSE,"<p>Given our experience that tests are the only API specifications that really matter, we're always on the lookout for new tools that might help with testing. <strong><a href=""https://intuit.github.io/karate/"">Karate</a></strong> is an API testing framework whose unique feature is that tests are written in Gherkin-based syntax without relying on a general-purpose programming language to implement test behavior. Karate uses a domain-specific language for describing HTTP-based API tests. Our teams like the readable specification that they get with this tool and recommend to keep tests with Karate in the upper levels of the <a href=""https://martinfowler.com/articles/practical-test-pyramid.html"">testing pyramid</a> and not overload its use by making very detailed assertions.</p>"
Sarama,Trial,languages-and-frameworks,FALSE,"<p><strong><a href=""https://github.com/Shopify/sarama"">Sarama</a></strong> is a Go client library for <a href=""/radar/tools/apache-kafka"">Apache Kafka</a>. If you’re developing your APIs in Go, you'll find Sarama quite easy to set up and manage as it doesn't depend on any native libraries. Sarama has two types of APIs — a high-level API for easily producing and consuming messages and a low-level API for controlling bytes on the wire.</p>"
Tamer,Assess,languages-and-frameworks,FALSE,"<p>If you need to ingest data from relational databases into a Kafka topic, consider <strong><a href=""https://github.com/laserdisc-io/tamer"">Tamer</a></strong>, which labels itself ""a domesticated JDBC source connector for Kafka."" Despite being a relatively new framework, we've found Tamer to be more efficient than the Kafka JDBC connector, especially when huge amounts of data are involved.</p>"
Wire,Assess,languages-and-frameworks,FALSE,"<p>The Golang community has had its fair share of dependency injection skeptics, partly because they confused the <a href=""https://martinfowler.com/articles/injection.html"">pattern</a> with specific frameworks, and developers with a system-programming background naturally dislike runtime overhead caused by reflection. Then along came <strong><a href=""https://github.com/google/wire"">Wire</a></strong>, a compile-time dependency injection tool that can generate code and wire components together. Wire has no additional runtime overhead, and the static dependency graph is easier to reason about. Whether you handwrite your code or use frameworks, we recommend using dependency injection to encourage modular and testable designs.</p>"